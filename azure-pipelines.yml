# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- master

jobs:
- job: build

  pool:
    vmImage: 'ubuntu-latest'

  variables:
    arc_version: '2.8.1'
    arc-jupyter_version: '2.0.3'
    spark_version: '2.4.5'

  timeoutInMinutes: 360
  steps:
  - script: |
      docker login --username $(DOCKER_HUB_USERNAME) --password $(DOCKER_HUB_PASSWORD)
    displayName: 'login to docker hub to allow push (https://hub.docker.com/u/triplai)'


  - script: |
    docker run \
    -it \
    -v $(pwd):/src \
    -e MAVEN_OPTS="-Xmx4g -XX:ReservedCodeCacheSize=2g" \
    -w /src \
    triplai/spark-rm:latest \
    ./dev/make-distribution.sh  \
    --pip \
    --r \
    --tgz \
    -Psparkr \
    -Phadoop-2.7 \
    -Phive \
    -Phive-thriftserver \
    -Pmesos \
    -Pyarn \
    -Pkubernetes \
    -Phadoop-2.9.2 \
    -Pscala-2.12

  - script: |
      export VERSION=$(cat arc/version) && \
      export SCALA_VERSION=2.11 && \
      export ARC_VERSION=$(arc_version) && \
      export SPARK_VERSION=$(spark_version) && \
      export HADOOP_VERSION=2.9.2 && \
      docker build . \
        -f arc/Dockerfile_${SCALA_VERSION} \
        --build-arg ARC_VERSION \
        --build-arg SPARK_VERSION \
        --build-arg HADOOP_VERSION \
        -t triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker push triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker rmi --force $(docker images -q triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION})
    displayName: 'build triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_2.11_hadoop_2.9.2_${VERSION}'

  - script: |
      export VERSION=$(cat arc/version) && \
      export SCALA_VERSION=2.12 && \
      export ARC_VERSION=$(arc_version) && \
      export SPARK_VERSION=$(spark_version) && \
      export HADOOP_VERSION=2.9.2 && \
      docker build . \
        -f arc/Dockerfile_${SCALA_VERSION} \
        --build-arg ARC_VERSION \
        --build-arg SPARK_VERSION \
        --build-arg HADOOP_VERSION \
        -t triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker push triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker rmi --force $(docker images -q triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION})
    displayName: 'build triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_2.12_hadoop_2.9.2_${VERSION}'

  - script: |
      export VERSION=$(cat arc/version) && \
      export SCALA_VERSION=2.11 && \
      export ARC_VERSION=$(arc_version) && \
      export SPARK_VERSION=$(spark_version) && \
      export HADOOP_VERSION=2.7.7 && \
      docker build . \
        -f arc/Dockerfile_${SCALA_VERSION} \
        --build-arg ARC_VERSION \
        --build-arg SPARK_VERSION \
        --build-arg HADOOP_VERSION \
        -t triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker push triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker rmi --force $(docker images -q triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION})
    displayName: 'build triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_2.11_hadoop_2.7.7_${VERSION}'

  - script: |
      export VERSION=$(cat arc/version) && \
      export SCALA_VERSION=2.12 && \
      export ARC_VERSION=$(arc_version) && \
      export SPARK_VERSION=$(spark_version) && \
      export HADOOP_VERSION=2.7.7 && \
      docker build . \
        -f arc/Dockerfile_${SCALA_VERSION} \
        --build-arg ARC_VERSION \
        --build-arg SPARK_VERSION \
        --build-arg HADOOP_VERSION \
        -t triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker push triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker rmi --force $(docker images -q triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION})
    displayName: 'build triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_2.12_hadoop_2.7.7_${VERSION}'

  - script: |
      export VERSION=$(cat arc-jupyter/version) && \
      export SCALA_VERSION=2.11 && \
      export ARC_JUPYTER_VERSION=$(arc-jupyter_version) && \
      export SPARK_VERSION=$(spark_version) && \
      export HADOOP_VERSION=2.9.2 && \
      docker build . \
      -f arc-jupyter/Dockerfile_${SCALA_VERSION} \
      --build-arg ARC_JUPYTER_VERSION \
      --build-arg SPARK_VERSION \
      --build-arg HADOOP_VERSION \
      -t triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker push triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker rmi --force $(docker images -q triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION})
    displayName: 'build triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_2.11_hadoop_2.9.2_${VERSION}'

  - script: |
      export VERSION=$(cat arc-jupyter/version) && \
      export SCALA_VERSION=2.12 && \
      export ARC_JUPYTER_VERSION=$(arc-jupyter_version) && \
      export SPARK_VERSION=$(spark_version) && \
      export HADOOP_VERSION=2.9.2 && \
      docker build . \
      -f arc-jupyter/Dockerfile_${SCALA_VERSION} \
      --build-arg ARC_JUPYTER_VERSION \
      --build-arg SPARK_VERSION \
      --build-arg HADOOP_VERSION \
      -t triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker push triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker rmi --force $(docker images -q triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION})
    displayName: 'build triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_2.12_hadoop_2.9.2_${VERSION}'

  - script: |
      export VERSION=$(cat arc-jupyter/version) && \
      export SCALA_VERSION=2.11 && \
      export ARC_JUPYTER_VERSION=$(arc-jupyter_version) && \
      export SPARK_VERSION=$(spark_version) && \
      export HADOOP_VERSION=2.7.7 && \
      docker build . \
      -f arc-jupyter/Dockerfile_${SCALA_VERSION} \
      --build-arg ARC_JUPYTER_VERSION \
      --build-arg SPARK_VERSION \
      --build-arg HADOOP_VERSION \
      -t triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker push triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker rmi --force $(docker images -q triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION})
    displayName: 'build triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_2.11_hadoop_2.7.7_${VERSION}'

  - script: |
      export VERSION=$(cat arc-jupyter/version) && \
      export SCALA_VERSION=2.12 && \
      export ARC_JUPYTER_VERSION=$(arc-jupyter_version) && \
      export SPARK_VERSION=$(spark_version) && \
      export HADOOP_VERSION=2.7.7 && \
      docker build . \
      -f arc-jupyter/Dockerfile_${SCALA_VERSION} \
      --build-arg ARC_JUPYTER_VERSION \
      --build-arg SPARK_VERSION \
      --build-arg HADOOP_VERSION \
      -t triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker push triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION} && \
      docker rmi --force $(docker images -q triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION})
    displayName: 'build triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_2.12_hadoop_2.7.7_${VERSION}'
